Probados con Azure azure_inference
cohere cmd r - es lento y no tan inteligente
Phi-3-small instruct (128k) - rápido pero es bueno infiriendo
Mistral-nemo - rapido y bueno haciedno inferencia, pero escribe solo en ingles
Mistral-large - lento y no tan bueno haciendo inferencias, mezcla español e ingles en las respuestas
meta-llama-3.1-70b-instruct - lento, medio infiriendo, hay que ser muy preciso al hacer preguntas

gpt-4o-mini - rapido per alucina un poco
gpt-4o - el mas rapido y preciso
